{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Submission\n",
    "\n",
    "This notebook will be your project submission. All tasks will be listed in the order of the Courses that they appear in. The tasks will be the same as in the Capstone Example Notebook, but in this submission you ___MUST___ use another dataset. Failure to do so will result in a large penalty to your grade in this course.\n",
    "\n",
    "## Finding your dataset\n",
    "\n",
    "Take some time to find an interesting dataset! There is a reading discussing various places where datasets can be found, but if you are able to process it, go ahead and use it! Do note, for some tasks in this project, each entry will need 3+ attributes, so keep that in mind when finding datasets. After you have found your dataset, the tasks will continue as in the Example Notebook. You will be graded based on the tasks and your results. Best of luck!\n",
    "\n",
    "### As Reviewer: \n",
    "Your job will be to verify the calculations made at each \"TODO\" labeled throughout the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Step: Imports\n",
    "\n",
    "In the next cell we will give you all of the imports you should need to do your project. Feel free to add more if you would like, but these should be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "import string\n",
    "from sklearn import linear_model\n",
    "from nltk.stem.porter import PorterStemmer # Stemming\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Data Processing\n",
    "\n",
    "### TODO 1: Read the data and Fill your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data to a pandas dataframe\n",
    "#df = pd.read_csv (\"C:/Users/45517/Desktop/Capstone_project/Data/amazon_reviews_us_Home_Improvement_v1_00.tsv\", sep=\"\\t\", encoding = \"utf-8\", names=('marketplace', 'customer_id', 'review_id', 'product_id', 'product_parent', 'product_title', 'product_category', 'star_rating', 'helpful_votes', 'total_votes', 'vine', 'verified_purchase', 'review_headline', 'review_body', 'review_date'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset comes from the original source - I could not find the cleaned version mentioned in the course material. \n",
    "So a bit of preliminary cleaning is necessary: \n",
    "- 1.1 remove rows with missing values\n",
    "- 1.2 remove row 1 - header duplication\n",
    "- 1.3 convert to int: star_rating, helpful_votes, total_votes\n",
    "- 1.4 convert to bool: vine, verified_purchase\n",
    "- 1.5 convert to datetime: review_date\n",
    "- 1.6 check consistency and quality of key columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 remove rows with missing values\n",
    "missing_values_count = df.isnull().sum()\n",
    "missing_values_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#count of the number of rows removed - not too bad. \n",
    "df1 = df.dropna()\n",
    "(len(df), len(df1), len(df)-len(df1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 remove row 1 - header duplication\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df2 = df1.drop(0, axis = 0)\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#we should reset index as we have deleted rows in 1.1 and 1.2\n",
    "df3 = df2.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 convert to int: star_rating, helpful_votes, total_votes\n",
    "# we start with letting pandas find the best typefit\n",
    "df3 = df3.convert_dtypes()\n",
    "df3.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df3[\"star_rating\"] = pd.to_numeric(df3[\"star_rating\"], downcast=\"signed\")\n",
    "df3[\"helpful_votes\"] = pd.to_numeric(df3[\"helpful_votes\"], downcast=\"signed\")\n",
    "df3[\"total_votes\"] = pd.to_numeric(df3[\"total_votes\"], downcast=\"signed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 convert to bool: vine, verified_purchase\n",
    "d = {'Y': True, 'N': False}\n",
    "df3[\"vine\"].map(d)\n",
    "df3[\"verified_purchase\"].map(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5 convert to datetime: review_date\n",
    "#looks like some of the dates are non-valid\n",
    "date_lengths = df3.review_date.str.len()\n",
    "date_lengths.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "indices = np.where([date_lengths == 1])[1]\n",
    "indices = indices\n",
    "print('Indices with corrupted data:', indices)\n",
    "df3.loc[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df4 = df3.drop(indices, axis = 0)\n",
    "date_lengths = df4.review_date.str.len()\n",
    "date_lengths.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#change timestamp to datetime type\n",
    "df4[\"review_date\"] = pd.to_datetime(df4[\"review_date\"], format=\"%Y-%M-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Convert to show date only\n",
    "df4[\"review_date\"] = df4[\"review_date\"].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#change timestamp to datetime type\n",
    "df4[\"review_date\"] = pd.to_datetime(df4[\"review_date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#create column with month and year stamp\n",
    "df4['month_year'] = df4[\"review_date\"].dt.to_period('M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.6 check the first rows in the dataset to see that things look fine\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2: Split the data into a Training and Testing set\n",
    "\n",
    "First shuffle your data, then split your data. Have Training be the first 80%, and testing be the remaining 20%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#shuffle the dataset in the dataframe format\n",
    "df4 = df4.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Split the dataset\n",
    "N = len(df4)\n",
    "T = round(N*0.8)\n",
    "#V = round(N*0.2)\n",
    "TE = round(N*0.2)\n",
    "full_tr = df4[:T]\n",
    "#X_validation = X[T:T+V]\n",
    "full_test = df4[T:N]\n",
    "#y_train = y[:T]\n",
    "#y_validation = y[T:T+V]\n",
    "#y_test = y[T+V:N]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Check the split\n",
    "(len(df4), len(full_tr), len(full_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the testset and the trainingset\n",
    "#full_tr.to_csv(\"C:/Users/45517/Desktop/Capstone_project/Data/full_train.csv\", index=False)\n",
    "#full_test.to_csv(\"C:/Users/45517/Desktop/Capstone_project/Data/full_test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now delete your dataset\n",
    "You don't want any of your answers to come from your original dataset any longer, but rather your Training Set, this will help you to not make any mistakes later on, especialy when referencing the checkpoint solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT! READ!\n",
    "# Not sure why delete the full dataset. I will disable everything until this step once executed - via markdown mode. \n",
    "# So the training and test set are shuffled and saved once - and from here we read and use the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the trainingset\n",
    "ft = pd.read_csv (\"C:/Users/45517/Desktop/Capstone_project/Data/full_train.csv\", sep=\",\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>month_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1073134</td>\n",
       "      <td>US</td>\n",
       "      <td>30601198</td>\n",
       "      <td>R1L9PM379H1VH5</td>\n",
       "      <td>B0000CBIFD</td>\n",
       "      <td>389336482</td>\n",
       "      <td>Frost King R338H Sponge Rubber Foam Tape 3/16-...</td>\n",
       "      <td>Home Improvement</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>works as intended</td>\n",
       "      <td>2014-01-12</td>\n",
       "      <td>2014-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1917516</td>\n",
       "      <td>US</td>\n",
       "      <td>17463604</td>\n",
       "      <td>R346HYHY50CXOJ</td>\n",
       "      <td>B004EMNIQ8</td>\n",
       "      <td>623424728</td>\n",
       "      <td>Intertape Polymer Group 6555SL AC6 6mil  Utili...</td>\n",
       "      <td>Home Improvement</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Not the stickiest duct tape</td>\n",
       "      <td>This is not the stickiest duct tape out there ...</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>272957</td>\n",
       "      <td>US</td>\n",
       "      <td>13669558</td>\n",
       "      <td>R247HKWHM64AX5</td>\n",
       "      <td>B00DPVLTP6</td>\n",
       "      <td>214607005</td>\n",
       "      <td>Factop Light Strip Waterproof 5M IC6803 5050 D...</td>\n",
       "      <td>Home Improvement</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>They are about as waterproof as your shoes wou...</td>\n",
       "      <td>These are NOT WATERPROOF.  They are about as w...</td>\n",
       "      <td>2015-01-22</td>\n",
       "      <td>2015-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index marketplace  customer_id       review_id  product_id  \\\n",
       "0  1073134          US     30601198  R1L9PM379H1VH5  B0000CBIFD   \n",
       "1  1917516          US     17463604  R346HYHY50CXOJ  B004EMNIQ8   \n",
       "2   272957          US     13669558  R247HKWHM64AX5  B00DPVLTP6   \n",
       "\n",
       "   product_parent                                      product_title  \\\n",
       "0       389336482  Frost King R338H Sponge Rubber Foam Tape 3/16-...   \n",
       "1       623424728  Intertape Polymer Group 6555SL AC6 6mil  Utili...   \n",
       "2       214607005  Factop Light Strip Waterproof 5M IC6803 5050 D...   \n",
       "\n",
       "   product_category  star_rating  helpful_votes  total_votes vine  \\\n",
       "0  Home Improvement            5              0            0    N   \n",
       "1  Home Improvement            3              0            0    N   \n",
       "2  Home Improvement            1              0            0    N   \n",
       "\n",
       "  verified_purchase                                    review_headline  \\\n",
       "0                 Y                                         Five Stars   \n",
       "1                 Y                        Not the stickiest duct tape   \n",
       "2                 Y  They are about as waterproof as your shoes wou...   \n",
       "\n",
       "                                         review_body review_date month_year  \n",
       "0                                  works as intended  2014-01-12    2014-01  \n",
       "1  This is not the stickiest duct tape out there ...  2013-01-01    2013-01  \n",
       "2  These are NOT WATERPROOF.  They are about as w...  2015-01-22    2015-01  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft[\"review_date\"] = pd.to_datetime(ft[\"review_date\"])\n",
    "ft['month_year'] = ft[\"review_date\"].dt.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                         int64\n",
       "marketplace                  object\n",
       "customer_id                   int64\n",
       "review_id                    object\n",
       "product_id                   object\n",
       "product_parent                int64\n",
       "product_title                object\n",
       "product_category             object\n",
       "star_rating                   int64\n",
       "helpful_votes                 int64\n",
       "total_votes                   int64\n",
       "vine                         object\n",
       "verified_purchase            object\n",
       "review_headline              object\n",
       "review_body                  object\n",
       "review_date          datetime64[ns]\n",
       "month_year                period[M]\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 3: Extracting Basic Statistics\n",
    "\n",
    "Next you need to answer some questions through any means (i.e. write a function or just find the answer) all based on the __Training Set:__\n",
    "1. How many entries are in your dataset?\n",
    "2. Pick a non-trivial attribute (i.e. verified purchases in example), what percentage of your data has this attribute?\n",
    "3. Pick another different non-trivial attribute, what percentage of your data share both attributes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35762866, 2103698, (2103698, 17), 17.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.1 Number of entries in the full training set\n",
    "total_cells = np.product(ft.shape)\n",
    "total_rows = len(ft)\n",
    "total_columns = ft.shape\n",
    "(total_cells, total_rows, total_columns, total_cells/total_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y    1884858\n",
       "N     218840\n",
       "Name: verified_purchase, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.2 Pick a non-trivial attribute (i.e. verified purchases in example), what percentage of your data has this attribute?\n",
    "ft[\"verified_purchase\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ys = 1884858, Ns = 218840, ratio of Ys = 89.6%\n"
     ]
    }
   ],
   "source": [
    "Y = (ft[\"verified_purchase\"] == \"Y\").sum() \n",
    "N = (ft[\"verified_purchase\"] == \"N\").sum() \n",
    "print (\"Ys = \" + str(Y) + \", Ns = \" + str(N) + \", ratio of Ys = \" + str(round(Y/(Y+N)*100, 2))+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One star ratings = 196683, total ratings = 2103698, ratio of one star ratings = 9.35%\n"
     ]
    }
   ],
   "source": [
    "# 3.3 Pick another different non-trivial attribute, what percentage of your data share both attributes?\n",
    "# how many received a one star rating?\n",
    "ones = (ft[\"star_rating\"] == 1).sum() \n",
    "total = len(ft) \n",
    "print (\"One star ratings = \" + str(ones) + \", total ratings = \" + str(total) + \", ratio of one star ratings = \" + str(round(ones/total*100, 2))+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verified one-star ratings = 154532, ratio of total verified ratings = 8.2%\n"
     ]
    }
   ],
   "source": [
    "#Of the verified purchases, how many received a one star rating?\n",
    "verified_ones = ((ft[\"verified_purchase\"] == \"Y\") & (ft[\"star_rating\"] == 1)).sum()\n",
    "print(\"verified one-star ratings = \" + str(verified_ones) + \", ratio of total verified ratings = \" + str(round(verified_ones/Y*100, 2)) + \"%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1440129"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.4 How many unique users are there in the dataset?\n",
    "unique_users = ft.customer_id.value_counts().count()\n",
    "unique_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310623"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many unique products are there in the dataset?\n",
    "unique_products = ft.product_id.value_counts().count()\n",
    "unique_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.103698e+06\n",
       "mean     4.181956e+00\n",
       "std      1.303085e+00\n",
       "min      1.000000e+00\n",
       "25%      4.000000e+00\n",
       "50%      5.000000e+00\n",
       "75%      5.000000e+00\n",
       "max      5.000000e+00\n",
       "Name: star_rating, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.5 What is the average rating?\n",
    "ft.star_rating.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.182"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(ft.star_rating.mean(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2103698"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#histogram of key columns\n",
    "ft.hist(column='star_rating')\n",
    "len(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8650"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vine = ft[ft[\"vine\"] == \"Y\"]\n",
    "vine.hist(column = \"star_rating\")\n",
    "len(vine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Classification\n",
    "\n",
    "Next you will use our knowledge of classification to extract features and make predictions based on them. Here you will be using a Logistic Regression Model, keep this in mind so you know where to get help from.\n",
    "\n",
    "### TODO 1: Define the feature function\n",
    "\n",
    "This implementation will be based on ___any two___ attributes from your dataset. You will be using these two attributes to predict a third. Hint: Remember the offset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression is covered in week 4 of 'design thinking and predictive analytics form data products': \n",
    "# See 'Classification in Python'-video and 'Gradient descent in Python'-video\n",
    "# Accuracy is covered in week 1 of 'meaningful predictive modeling' - 'classification diagnostics: accuracy and error'video\n",
    "# Regularizer is covered in week 2 of 'meaningful predictive modelling' - Adding a Regularizer to our Model, and Evaluating the Regularized Model - video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use 3 attributes (customer_id, review length, star rating) to predict verified_purchase\n",
    "# If the model is of any value it should beat the Y/Total-ratio for verified_purchase, \n",
    "# or always predicting five stars, which is the most common star rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(d):\n",
    "    feat = [1, len(d['review_body']), d[\"customer_id\"], d[\"star_rating\"]]\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2: Fit your model\n",
    "\n",
    "1. Create your __Feature Vector__ based on your feature function defined above. \n",
    "2. Create your __Label Vector__ based on the \"verified purchase\" column of your training set.\n",
    "3. Define your model as a __Logistic Regression__ model.\n",
    "4. Fit your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_sample = ft[:500000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the feature vector\n",
    "X = np.array([feature(var) for var in ft_sample.iloc()])\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the label vector\n",
    "y = np.array([var[\"verified_purchase\"] for var in ft_sample.iloc()])\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\45517\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the model defined and data fitted\n",
    "model = linear_model.LogisticRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 3: Compute Accuracy of Your Model\n",
    "\n",
    "1. Make __Predictions__ based on your model.\n",
    "2. Compute the __Accuracy__ of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Y', 'Y', 'Y', ..., 'Y', 'Y', 'Y'], dtype='<U1')"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make predictions\n",
    "predictions = model.predict(X)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     500000\n",
       "unique         2\n",
       "top            Y\n",
       "freq      494112\n",
       "dtype: object"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert predicted output to pd.series and describe\n",
    "predictionseries = pd.Series(predictions)\n",
    "predictionseries.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448898"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#correctpredictions\n",
    "correctpredictions = predictions == y\n",
    "sum(correctpredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.897796"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy\n",
    "accuracy = sum(correctpredictions)/len(correctpredictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896168"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Default position - just assume \"Y\" all the time \n",
    "Y = (ft_sample[\"verified_purchase\"] == \"Y\").sum() \n",
    "default = Y/len(correctpredictions)\n",
    "default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# follows that the model perform slightly better than the default position which is to predict 'y' every time. \n",
    "# Note that it is on the training set! \n",
    "\n",
    "#also note: the input to the model has to be arrays (np.array)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Regression\n",
    "\n",
    "In this section you will start by working though two examples of altering features to further differentiate. Then you will work through how to evaluate a Regularaized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_sample1 = ft.iloc[:500000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                         int64\n",
       "marketplace                  object\n",
       "customer_id                   int64\n",
       "review_id                    object\n",
       "product_id                   object\n",
       "product_parent                int64\n",
       "product_title                object\n",
       "product_category             object\n",
       "star_rating                   int64\n",
       "helpful_votes                 int64\n",
       "total_votes                   int64\n",
       "vine                         object\n",
       "verified_purchase            object\n",
       "review_headline              object\n",
       "review_body                  object\n",
       "review_date          datetime64[ns]\n",
       "month_year                period[M]\n",
       "dtype: object"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_sample1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 1: Unique Words in a Sample Set\n",
    "\n",
    "We are going to work with a new dataset here, as such we are going to take a smaller portion of the set and call it a Sample Set. This is because stemming on the normal training set will take a very long time. (Feel free to change sampleSet -> reg_dataset if you would like to see the difference for yourself)\n",
    "\n",
    "1. Count the number of unique words found within the 'review body' portion of the sample set defined below, making sure to __Ignore Punctuation and Capitalization__.\n",
    "2. Count the number of unique words found within the 'review body' portion of the sample set defined below, this time with use of __Stemming,__ __Ignoring Puctuation,__ ___and___ __Capitalization__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3.2: Engineering the text column\n",
    "\n",
    "# removes punctuation and upper case and creates a dict with count of all the words in the text column\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in ft_sample1.iloc():\n",
    "    r = ''.join([c for c in d[\"review_body\"].lower() if not c in punctuation]) # removes punctuation and upper case\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1 # creates a count of all the words in the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WITH STEMMER - add Stemmer to the engineering\n",
    "wordCountStem = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "stemmer = PorterStemmer()\n",
    "for d in ft_sample1.iloc():\n",
    "    r = ''.join([c for c in d[\"review_body\"].lower() if not c in punctuation]) # removes punctuation and upper case\n",
    "    for w in r.split():\n",
    "        w = stemmer.stem(w)\n",
    "        wordCountStem[w] += 1 # creates a count of all the words in the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR THE NON-STEMMED VERSION\n",
    "#sort the list of words descending\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "# create a list of the 1000 most used words\n",
    "words = [x[1] for x in counts[:500]]\n",
    "\n",
    "# create a dict and set of the 100 most used words\n",
    "wordID = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR THE STEMMED VERSION\n",
    "#sort the list of words descending\n",
    "countsStem = [(wordCountStem[w], w) for w in wordCountStem]\n",
    "countsStem.sort()\n",
    "countsStem.reverse()\n",
    "\n",
    "# create a list of the 1000 most used words\n",
    "wordsStem = [x[1] for x in counts[:200]]\n",
    "\n",
    "# create a dict and set of the 100 most used words\n",
    "wordIDStem = dict(zip(wordsStem, range(len(wordsStem))))\n",
    "wordSetStem = set(wordsStem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2: Evaluating Classifiers\n",
    "\n",
    "1. Given the feature function and your counts vector, __Define__ your X_reg vector. (This being the X vector, simply labeled for the Regression model)\n",
    "2. __Fit__ your model using a __Ridge Model__ with (alpha = 1.0, fit_intercept = True).\n",
    "3. Using your model, __Make your Predictions__.\n",
    "4. Find the __MSE__ between your predictions and your y_reg vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will only run the non-stemmer model - due to compute constraints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function needed to create a list for a particular review\n",
    "def feature(datum):\n",
    "    feat = [0]*len(words) # list of 1000 zeros\n",
    "    r = ''.join([c for c in datum['review_body'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in words:\n",
    "            feat[wordID[w]] +=1\n",
    "    feat.append(1) # add the offset dimension\n",
    "    return feat\n",
    "\n",
    "#the function that will evaluate the model\n",
    "def accuracy(model, X, y):\n",
    "    predictionsreg = model.predict(X)\n",
    "    correctpredictionsreg = predictionsreg == y\n",
    "    return sum(correctpredictionsreg)/len(correctpredictionsreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saves the most accurate model\n",
    "bestModel = None\n",
    "bestaccuracy = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature input - note it is a numpy.array\n",
    "X_reg = np.array([feature(d) for d in ft_sample1.iloc()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-355-978a8916121e>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ft_sample1['verified_purchase1'] = ft_sample1.apply(lambda row: normer(row), axis=1)\n"
     ]
    }
   ],
   "source": [
    "#change label column from Y/N to 1/0\n",
    "def normer(var):\n",
    "    d = var\n",
    "    if d[\"verified_purchase\"] == \"Y\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "ft_sample1['verified_purchase1'] = ft_sample1.apply(lambda row: normer(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ft_sample1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label column - also numpy array\n",
    "y_reg = np.array([d[\"verified_purchase1\"] for d in ft_sample1.iloc()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 0.0001 , training/(validation) accuracy = 0.897392\n",
      "lambda = 0.001 , training/(validation) accuracy = 0.897392\n",
      "lambda = 0.01 , training/(validation) accuracy = 0.897392\n",
      "lambda = 1 , training/(validation) accuracy = 0.89739\n"
     ]
    }
   ],
   "source": [
    "#fits the model and calculates accuracy (note the it is RidgeClassifier that is used)\n",
    "for lamb in (0.0001, 0.001, 0.01, 1):\n",
    "    modelreg = linear_model.RidgeClassifier(alpha=lamb, fit_intercept = False)\n",
    "    modelreg.fit(X_reg, y_reg)\n",
    "    \n",
    "    accuracyTrain = accuracy(modelreg, X_reg, y_reg)\n",
    "    #mseValidation = MSE(model, X_validation, y_validation)\n",
    "\n",
    "    print(\"lambda = \" + str(lamb) + \" , training/(validation) accuracy = \" + str(accuracyTrain))# + \"/\" + str(mseValidation))\n",
    "    if not bestModel or accuracyTrain < bestaccuracy:\n",
    "        bestModel = model\n",
    "        bestaccuracy = accuracyTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 500, Ridge(alpha=0.01, fit_intercept=False), 0.89739)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output of the best fit model\n",
    "(len(X), len(words), bestModel, round(bestaccuracy, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the accuracy of the models in task 2 and task 3. Almost same performance, but the Task 2 model is slightly better\n",
    "#could be interesting to combine them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Recommendation Systems\n",
    "\n",
    "For your final task, you will use your knowledge of simple similarity-based recommender systems to make calculate the most similar items.\n",
    "\n",
    "The next cell contains some starter code that you will need for your tasks in this section.\n",
    "Notice you should be back to using your __trainingSet__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant videos: Deploying machine learning models: Week 1 - collaborative filtering-based recommendation video, \n",
    "# Week 2 - Implementing a similarity-based recommender, week 2 - Similarity based recommender for Rating prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use customer_id and product_parent as key columns. product_parent corresponds best to product_title. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_sample4 = ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates 2 default lists in the set format: 1 to contain sets of all products per customer and 1 to contain sets of all customers per product\n",
    "customersperproduct = defaultdict(set)\n",
    "productspercustomer = defaultdict(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a dictionary of all to lookup product titles so that product parents make sense - we can compare whether a recommendation \n",
    "# seems to make sense (items that would be bought together)\n",
    "itemNames = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 1: Fill your Dictionaries\n",
    "\n",
    "1. For each entry in your training set, fill your default dictionaries (defined above). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we populate the dictionaries\n",
    "for d in ft_sample4.iloc:\n",
    "    customer,product = d[\"customer_id\"],d[\"product_parent\"]\n",
    "    customersperproduct[product].add(customer)\n",
    "    productspercustomer[customer].add(product)\n",
    "    itemNames[product] = d[\"product_title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the Jaccard similarity\n",
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    return numer / denom\n",
    "\n",
    "#calculate and sort the similar item - candidateproducts loop speeds up the process by only looking at relevant product \n",
    "def mostSimilar(n, m): #n is the entry index, #m is the number of entries\n",
    "    similarities = []  \n",
    "    users = customersperproduct[n]\n",
    "    candidateproducts = set()\n",
    "    for u in users:\n",
    "        candidateproducts = candidateproducts.union(productspercustomer[u])    \n",
    "    for i2 in candidateproducts:\n",
    "        if i2 == n: continue\n",
    "        sim = Jaccard(users, customersperproduct[i2])\n",
    "        similarities.append((sim,i2))\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[:m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 1: Fill your Dictionaries\n",
    "\n",
    "1. Calculate the __10__ most similar entries to the __first__ entry in your dataset, using the functions defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0425531914893617, 746424642),\n",
       " (0.03773584905660377, 459620076),\n",
       " (0.037037037037037035, 965101388),\n",
       " (0.037037037037037035, 925022928),\n",
       " (0.037037037037037035, 744593919),\n",
       " (0.037037037037037035, 663256728),\n",
       " (0.037037037037037035, 526186588),\n",
       " (0.037037037037037035, 373323101),\n",
       " (0.037037037037037035, 88680219),\n",
       " (0.037037037037037035, 67573513)]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example\n",
    "#input\n",
    "query = ft_sample4.loc[1][\"product_parent\"]\n",
    "#output\n",
    "mostSimilar(query, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Intertape Polymer Group 6555SL AC6 6mil  Utility Grade Duct Tape, 1.88-Inch x 55-Yard, Silver, 3-Pack'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemNames[query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brinks Home Security Push Pull Rotate Door Locks Alwood Entry Lever',\n",
       " '3-IN-ONE Oil No Rust Shield Rust & Corrosion Inhibitor (Pack of 12)',\n",
       " 'BOSCH POWER TOOLS\\xa0Replacement Part 2610967697\\xa0Use Accessory',\n",
       " 'BOSCH POWER TOOLS\\xa0Replacement Part 373094\\xa0Use Accessory',\n",
       " 'BOSCH POWER TOOLS\\xa0Replacement Part 318879\\xa0Use Accessory',\n",
       " '6885 1.18-Inch by 100-Yard Ribbon, Yellow, 12-Pack',\n",
       " 'Anchor 1/0-50 Cable Kitw/Ab-Lc40 M/F',\n",
       " 'BOSCH POWER TOOLS\\xa0Replacement Part 5048901\\xa0Use Accessory',\n",
       " 'Kenyon Express II B23200 13\" Portable Butane Gas Cooker with Carrying Case',\n",
       " 'BOSCH POWER TOOLS\\xa0Replacement Part 318802\\xa0Use Accessory']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[itemNames[x[1]] for x in mostSimilar(query,10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finished!\n",
    "\n",
    "Congratulations! You are now ready to submit your work. Once you have submitted make sure to get started on your peer reviews!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
